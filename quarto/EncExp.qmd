--- 
title: "CompStats"
format: 
  dashboard:
    logo: images/ingeotec.png
    orientation: columns
    nav-buttons: [github]
    theme: cosmo
execute:
  freeze: auto    
---

# Introduction

## Column 

::: {.card title='Introduction'}  
EncExp is a set of tools to create and use explainable embeddings.
:::

::: {.card title='Installing using pip'} 
A more general approach to installing `EncExp` is through the use of the command pip, as illustrated in the following instruction.

```{sh} 
pip install CompStats
```
::: 

# Corpus 

## Column 

::: {.card title="Description"}
Tweets have been collected from the open stream for several years, e.g., the Spanish collection started on December 11, 2015 (see the table on the left to know the starting collection date for each language). The collected Tweets were filtered with the following restrictions: the retweets were removed; URL and users were replaced by the tokens _url and _usr, respectively; and only tweets with at least 50 characters were accepted in the final collection, namely Corpus. 

The Corpus is divided into two distinct sets: the first set is utilized to construct the training set, while the second set corresponds to the test set. The basis for this division is a specific date, with tweets published prior to October 1, 2022, forming the first set, and those published on October 3, 2022, or later, being used to create the test set. 

The training set and test set were created with an equivalent procedure; the only difference is that the maximum size of the training set is 10M tweets and $2^{12}$ (4096) tweets for the test set.

The training and test set was meticulously crafted by uniformly selecting the maximum number of tweets (i.e., 10M and $2^{12}$, respectively) from each day. These selected tweets were then organized by day, and within each day, the tweets were randomly chosen, with near duplicates being removed. The subsequent step involved the elimination of tweets that were near duplicates of the previous three days.

It is worth mentioning that the last step is to shuffle the training and test set to eliminate the ordering by date. 
:::